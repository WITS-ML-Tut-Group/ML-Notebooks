{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed8354a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in c:\\users\\gampl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\gampl\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ipynb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd0f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.CleaningData import getDataset\n",
    "from ipynb.fs.full.CleaningData import getCovarianceVector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10000)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c648cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = getDataset(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "covVec = getCovarianceVector(df)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6)) # the figsize changes the width and height respectively\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = covVec.index\n",
    "students = covVec\n",
    "ax.bar(langs,students, align='edge', width=0.7) #width determines width of bars\n",
    "plt.xticks(rotation = 90) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11caca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating and storing y values (Status Feature)\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "statusColumn = df['status']\n",
    "del df['status']\n",
    "urlColumn = df['url']\n",
    "del df['url']\n",
    "\n",
    "# Printing the feature set\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Storing the number of features\n",
    "\n",
    "numFeatures = (len(df.columns)) \n",
    "# print(numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7f7a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.uniform(-0.5,0.5,numFeatures) # Initialising random theta values\n",
    "origTheta = theta # Keeping a copy of original theta values \n",
    "\n",
    "# Splitting data into test, validation and train\n",
    "trainX, testX, trainY, testY = train_test_split(df, statusColumn, test_size=0.15)\n",
    "trainX, validationX, trainY, validationY = train_test_split(trainX, trainY, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b953bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def sigmoid(x,k): #Sigmoid function\n",
    "    \n",
    "    if(k==0):\n",
    "        f = 1\n",
    "    else:\n",
    "        f = k\n",
    "    return 1/(1+np.exp(-f*x))\n",
    "\n",
    "def prediction(theta, x, k): #IPrediction function\n",
    "    return sigmoid(np.matmul(np.transpose(theta),x),k)\n",
    "\n",
    "def LogisticRegression(trainX, trainY, theta, a, regularisation): # Logistic Regression Algorithm\n",
    "    alpha = a\n",
    "    newTheta = theta\n",
    "    strengthOfRegularisation = regularisation\n",
    "    count = 0\n",
    "\n",
    "    while(count < 10):\n",
    "        oldTheta = newTheta\n",
    "        for i in trainX.index:\n",
    "            for j in range(numFeatures):\n",
    "                newTheta[j] = newTheta[j] + alpha*(trainY.loc[i] - prediction(newTheta,trainX.loc[i],strengthOfRegularisation))*(trainX.loc[i][j]) + alpha*strengthOfRegularisation*newTheta[j]\n",
    "        count = count + 1\n",
    "        \n",
    "    return newTheta\n",
    "\n",
    "def calculateAccuracy(x,y,theta,confusionMatrix, k): # Calculates the accuracy and create the confusion matrix\n",
    "    numberCorrect = 0\n",
    "    numberIncorrect = 0\n",
    "\n",
    "    for i in range(len(testY)):\n",
    "        \n",
    "        predicted_result = round(prediction(newTheta,testX.iloc[i], k))\n",
    "        \n",
    "        if(predicted_result == 1 and testY.iloc[i] == 0):\n",
    "            confusionMatrix[0] = confusionMatrix[0] + 1\n",
    "        else:\n",
    "            if (predicted_result == 0 and testY.iloc[i] == 1):\n",
    "                confusionMatrix[1] = confusionMatrix[1] + 1\n",
    "            else:\n",
    "                if(predicted_result == 1 and testY.iloc[i] == 1):\n",
    "                    confusionMatrix[2] = confusionMatrix[2] + 1\n",
    "                else:\n",
    "                    if(predicted_result == 0 and testY.iloc[i] == 0):\n",
    "                        confusionMatrix[3] = confusionMatrix[3] + 1\n",
    "                    \n",
    "        if(predicted_result == testY.iloc[i]):\n",
    "            numberCorrect = numberCorrect + 1\n",
    "        else:\n",
    "            numberIncorrect = numberIncorrect + 1\n",
    "            \n",
    "    averageCorrect = numberCorrect/len(testY)\n",
    "    averageIncorrect = numberIncorrect/len(testY)\n",
    "    \n",
    "    return averageCorrect*100, averageIncorrect*100, confusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5a3ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha =  0.01\n",
      "Regularisation =  0\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "815     78\n",
      "33     797\n",
      "==============================================\n",
      "Percentage Correct :  93.55774811375508\n",
      "Percentage Incorrect :  6.4422518862449225\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.01\n",
      "Regularisation =  0.001\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "739     154\n",
      "57     773\n",
      "==============================================\n",
      "Percentage Correct :  87.7539175856065\n",
      "Percentage Incorrect :  12.2460824143935\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.01\n",
      "Regularisation =  0.002\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "748     145\n",
      "55     775\n",
      "==============================================\n",
      "Percentage Correct :  88.39233894370284\n",
      "Percentage Incorrect :  11.607661056297156\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.01\n",
      "Regularisation =  0.01\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "784     109\n",
      "51     779\n",
      "==============================================\n",
      "Percentage Correct :  90.71387115496228\n",
      "Percentage Incorrect :  9.286128845037725\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.01\n",
      "Regularisation =  0.03\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "787     106\n",
      "41     789\n",
      "==============================================\n",
      "Percentage Correct :  91.4683691236216\n",
      "Percentage Incorrect :  8.53163087637841\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.001\n",
      "Regularisation =  0\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "806     87\n",
      "31     799\n",
      "==============================================\n",
      "Percentage Correct :  93.15147997678469\n",
      "Percentage Incorrect :  6.848520023215323\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.001\n",
      "Regularisation =  0.001\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "732     161\n",
      "55     775\n",
      "==============================================\n",
      "Percentage Correct :  87.46372605919908\n",
      "Percentage Incorrect :  12.53627394080093\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.001\n",
      "Regularisation =  0.002\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "733     160\n",
      "54     776\n",
      "==============================================\n",
      "Percentage Correct :  87.57980266976205\n",
      "Percentage Incorrect :  12.420197330237958\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.001\n",
      "Regularisation =  0.01\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "739     154\n",
      "53     777\n",
      "==============================================\n",
      "Percentage Correct :  87.98607080673244\n",
      "Percentage Incorrect :  12.013929193267558\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.001\n",
      "Regularisation =  0.03\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "748     145\n",
      "51     779\n",
      "==============================================\n",
      "Percentage Correct :  88.62449216482878\n",
      "Percentage Incorrect :  11.375507835171213\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.0001\n",
      "Regularisation =  0\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "661     232\n",
      "78     752\n",
      "==============================================\n",
      "Percentage Correct :  82.0081253627394\n",
      "Percentage Incorrect :  17.99187463726059\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.0001\n",
      "Regularisation =  0.001\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "669     224\n",
      "67     763\n",
      "==============================================\n",
      "Percentage Correct :  83.11085316308764\n",
      "Percentage Incorrect :  16.88914683691236\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.0001\n",
      "Regularisation =  0.002\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "669     224\n",
      "67     763\n",
      "==============================================\n",
      "Percentage Correct :  83.11085316308764\n",
      "Percentage Incorrect :  16.88914683691236\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.0001\n",
      "Regularisation =  0.01\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "670     223\n",
      "67     763\n",
      "==============================================\n",
      "Percentage Correct :  83.16889146836913\n",
      "Percentage Incorrect :  16.831108531630875\n",
      "============================================== \n",
      "\n",
      "Alpha =  0.0001\n",
      "Regularisation =  0.03\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "678     215\n",
      "69     761\n",
      "==============================================\n",
      "Percentage Correct :  83.51712130005804\n",
      "Percentage Incorrect :  16.48287869994196\n",
      "============================================== \n",
      "\n",
      "Wall time: 51min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = [] # Matrix to store validation results\n",
    "confusionMatrix = [0,0,0,0] # Confusion Matrix\n",
    "alphaArray = [0.01, 0.001, 0.0001] # Alpha Values\n",
    "regularisationArray = [0, 0.001, 0.002, 0.01, 0.03] # Regularisation values\n",
    "newTheta = []\n",
    "\n",
    "theta = np.random.uniform(-0.5,0.5,numFeatures) # Initialising random theta values\n",
    "origTheta = deepcopy(theta) # Keeping a copy of original theta values \n",
    "\n",
    "# Obtaining the optimal hyperparameters by getting the accuracy and confusion matrix for each hyperparameter\n",
    "\n",
    "r = 0\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        newTheta = LogisticRegression(validationX, validationY, theta, alphaArray[i], regularisationArray[j])\n",
    "        results.append(calculateAccuracy(testX,testY,newTheta,confusionMatrix, 0))\n",
    "        print(\"Alpha = \",alphaArray[i])\n",
    "        print(\"Regularisation = \", regularisationArray[j])\n",
    "        print(\"==============================================\")\n",
    "        print(\"Confusion Matrix\",'\\n' )\n",
    "        print(results[r][2][2],\"   \",results[r][2][1] )\n",
    "        print(results[r][2][0],\"   \",results[r][2][3] )\n",
    "        print(\"==============================================\")\n",
    "        print(\"Percentage Correct : \", results[r][0])\n",
    "        print(\"Percentage Incorrect : \", results[r][1])\n",
    "        print(\"==============================================\",'\\n')\n",
    "        theta = deepcopy(origTheta) \n",
    "        r = r + 1\n",
    "        confusionMatrix = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa596f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainingResults = []\n",
    "confusionMatrix = [0,0,0,0]\n",
    "newTheta = []\n",
    "\n",
    "theta = np.random.uniform(-0.5,0.5,numFeatures) # Initialising random theta values\n",
    "origTheta = deepcopy(theta) # Keeping a copy of original theta values \n",
    "\n",
    "# Obtaining the optimal values for theta by getting the accuracy and confusion matrix using the tuned hyperparameters\n",
    "\n",
    "newTheta = LogisticRegression(trainX, trainY, theta, 0.01, 0)\n",
    "trainingResults.append(calculateAccuracy(trainX, trainY, newTheta, confusionMatrix, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec12a38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha =  0.01\n",
      "Regularisation =  0\n",
      "==============================================\n",
      "Confusion Matrix \n",
      "\n",
      "820     73\n",
      "34     796\n",
      "==============================================\n",
      "Percentage Correct :  93.78990133488102\n",
      "Percentage Incorrect :  6.210098665118979\n",
      "============================================== \n",
      "\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Obtaining the test results by using new data on the model with trained theta values\n",
    "confusionMatrix = [0,0,0,0]\n",
    "\n",
    "testResults = []\n",
    "testResults.append(calculateAccuracy(testX, testY, newTheta, confusionMatrix, 0))\n",
    "print(\"Alpha = \",0.01)\n",
    "print(\"Regularisation = \", 0)\n",
    "print(\"==============================================\")\n",
    "print(\"Confusion Matrix\",'\\n' )\n",
    "print(testResults[0][2][2],\"   \",testResults[0][2][1] )\n",
    "print(testResults[0][2][0],\"   \",testResults[0][2][3] )\n",
    "print(\"==============================================\")\n",
    "print(\"Percentage Correct : \", testResults[0][0])\n",
    "print(\"Percentage Incorrect : \", testResults[0][1],)\n",
    "print(\"==============================================\",'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3cb441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
