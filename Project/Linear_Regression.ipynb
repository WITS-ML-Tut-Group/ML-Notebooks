{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1616c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install ipynb\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6473b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "\n",
    "from ipynb.fs.full.CleaningData import getDataset\n",
    "from ipynb.fs.full.CleaningData import getCovarianceVector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import unravel_index\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "np.set_printoptions(suppress=True)  # When displaying a numpy array, the values are NOT expressed in Scientific Notation\n",
    "# :) Please uncomment to use (if desired):\n",
    "# To use this you MIGHT need to run Jupyter Notebook with the following command: \n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "#np.set_printoptions(threshold=np.inf)  # Displays ALL rows and ALL columns - takes slightly more compute time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601d917",
   "metadata": {},
   "source": [
    "### Hyper Parameters\n",
    "The three global variables below are used in the validation dataset to find the best hyper paramters to be used for the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b2a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed-form Solution\n",
    "optimalLambda = 0\n",
    "\n",
    "# Gradient Descent\n",
    "optimalAlpha = 0\n",
    "optimalStopping = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59333a8",
   "metadata": {},
   "source": [
    "# Get Dataset\n",
    "\n",
    "The datatset is imported from CleaningData.ipynb. It prints all the columns that were deleted and the reason why. It also prints a dataframe of the first 100 records from the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dataset in a dataframe df\n",
    "df = getDataset(500)\n",
    "\n",
    "# Remove the URL column because it is not a feature - the features are based off the url\n",
    "urlColumn = df['url']\n",
    "del df['url']\n",
    "\n",
    "# Print the first 100 records in the dataframe\n",
    "# df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb024a3",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "\n",
    "We used a package called **sklearn** to split the dataset into Training Data, Testing Data, and Validation Data.\n",
    "\n",
    "The ratio is Training:Testing:Validation = 60:20:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbae7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for ratios (60:20:20)\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# trainX is split to be 60% of the entire data set and testX is 40% of the entire dataset\n",
    "trainX, testX, = train_test_split(df, test_size = 1 - train_ratio)\n",
    "\n",
    "# test is now 40% of the initial data set\n",
    "# testX is split further to create testX to be 20% and validationX (valX) to be 20% of the initial data set\n",
    "valX, testX = train_test_split(testX, test_size = test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "# The 'status' column is our target, so it is deleted from the features and stored as the true y values\n",
    "trainY = trainX['status']\n",
    "del trainX['status']\n",
    "testY = testX['status']\n",
    "del testX['status']\n",
    "valY = valX['status']\n",
    "del valX['status']\n",
    "\n",
    "# Print out the training data (x)\n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(trainX)  # At the bottom, it shows that trainX contains 6888 rows and 56 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10e459",
   "metadata": {},
   "source": [
    "# FUNCTIONS\n",
    "Before performing Linear Regression, we've created functions that are used in both solutions (closed-form and gradient descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777ec65",
   "metadata": {},
   "source": [
    "# Create Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d7c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create design matrix using the data given (xValues)\n",
    "def createDesignMatrix(xValues):\n",
    "    \n",
    "    # Initialise matrix filled with 1s\n",
    "    number_rows = len(xValues.index)\n",
    "    number_cols = len(xValues.columns) + 1\n",
    "    designMat = np.ones((number_rows, number_cols), dtype=float)\n",
    "\n",
    "    # For each feature (column) and url (row), add the value to the design matrix\n",
    "    for featureIndex in range(len(xValues.columns)):\n",
    "        for urlIndex in range(len(xValues.index)): \n",
    "\n",
    "            colName = xValues.columns[featureIndex]\n",
    "            designMat[urlIndex][featureIndex + 1] = xValues[colName][xValues.index[urlIndex]]\n",
    "    \n",
    "    return designMat\n",
    "\n",
    "designMatrix = createDesignMatrix(trainX)\n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(designMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dd98c",
   "metadata": {},
   "source": [
    "# Calculate Predicted y Values\n",
    "\n",
    "The predicted y values are the values we predicted using the `thetaVector`. \n",
    "\n",
    "The predicted y vales are calculated using the function:\n",
    "`y = ` $theta$$_{0}$ $+$ $theta$$_{1}$$*$$x_{1}$ $+$ $theta$$_{2}$$*$$x_{2}$ $+$ $...$ $+$ $theta$$_{n}$$*$$x_{n}$\n",
    "\n",
    "Predicted values are rounded because the `status` column (target) contains values of `0` (Legitimate) or `1` (Phishing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b020e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calulate predicted y values\n",
    "def calculateY(designMat, thetas):\n",
    "    \n",
    "    # Store predicted values in a vector\n",
    "    predictedY = []\n",
    "\n",
    "    # For every url\n",
    "    for urlIndex in range(len(designMat)):\n",
    "\n",
    "        # The function is really long because there are 57 features so we add each term in the for loop\n",
    "        # we begin by setting y to the theta0 (which is multiplied by 1 - the first element in the design matrix\n",
    "        # for each row)\n",
    "        y = thetas[0]\n",
    "\n",
    "        # For every feature (exluding the first element which is used above)\n",
    "        for j in range(1, len(designMat[urlIndex])): \n",
    "\n",
    "            y = y + designMat[urlIndex][j] * thetas[j]\n",
    "\n",
    "        # Rount the predicted y value\n",
    "        predictedY.append(round(y))\n",
    "\n",
    "    return predictedY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11665e1",
   "metadata": {},
   "source": [
    "# Create Confusion Matrix\n",
    "\n",
    "The functions `getConfusionMatrix()` calculates the confusion martix and `printConfusionMatrix()` prints it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6ab28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get confusion matrix data for making the matrix\n",
    "def getConfusionMatrix(predictedY, trueY):\n",
    "    \n",
    "    # For all URLs\n",
    "    amountDataPoints = len(predictedY)\n",
    "    \n",
    "    quad1 = 0\n",
    "    quad2 = 0\n",
    "    quad3 = 0\n",
    "    quad4 = 0\n",
    "    outliers = 0  # outliers is used for the case when the predicted y value is neither a 0 or 1 (outliers)\n",
    "\n",
    "    for i in range(amountDataPoints): \n",
    "        \n",
    "        if(trueY[trueY.index[i]] == 0):\n",
    "            \n",
    "            if (predictedY[i] == 0):\n",
    "                quad1 += 1\n",
    "            elif (predictedY[i] == 1):\n",
    "                quad2 += 1\n",
    "            else:\n",
    "                outliers += 1\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            if (predictedY[i] == 1):\n",
    "                quad4 += 1\n",
    "            elif (predictedY[i] == 0):\n",
    "                quad3 += 1\n",
    "            else:\n",
    "                outliers += 1\n",
    "\n",
    "        \n",
    "    return [quad1, quad2, quad3, quad4, outliers]\n",
    "        \n",
    "#Printing out confusion matrix\n",
    "def printConfusionMatrix(quad1, quad2, quad3, quad4, hyperParemeterSymbol, hyperParameterValue):\n",
    "    \n",
    "    print(hyperParemeterSymbol + \" is: \" + str(hyperParameterValue))\n",
    "    print(\"===========================\\n\")\n",
    "\n",
    "    print(\"===========================\")\n",
    "    print(\"Confusion Matrix\\n\")\n",
    "    print(\"Class\\t\\tLegitimate\\tPhishing\")\n",
    "    print(\"Legitimate\\t\"+str(quad1)+\"\\t\\t\"+str(quad2))\n",
    "    print(\"Phishing\\t\"+str(quad3)+\"\\t\\t\"+str(quad4))\n",
    "    print(\"\\n=========================\\n\")\n",
    "\n",
    "    accu = (quad1 + quad4)/(quad1 + quad2 + quad3 + quad4)\n",
    "    print(\"===========================\")\n",
    "    print(\"Accuracy of: \" + str(format(accu * 100,\".5f\")) + \" %\")\n",
    "    print(\"===========================\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f270f92",
   "metadata": {},
   "source": [
    "# TRAINING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f9efa",
   "metadata": {},
   "source": [
    "# Closed-Form Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60692e27",
   "metadata": {},
   "source": [
    "### Create theta vector\n",
    "Create vector which represents the **optimal solution for theta**\n",
    "\n",
    "The formula to determine the optimal solution for theta is:\n",
    "`theta =` $((X)^{Y}$$X)$$^{-1}$$(X^{T}$$y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8a166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the optimal theta vector\n",
    "def createOptimalTheta(lamda):\n",
    "    \n",
    "    # The identity matrix is used for regularisation\n",
    "    identityMatrix = np.identity(designMatrix.shape[1])\n",
    "    identityMatrix[0][0] = 0  # There is no regularisation on theta0\n",
    "\n",
    "    # Performing calculation:\n",
    "    transMatrix = designMatrix.transpose() #X^T\n",
    "\n",
    "    calcXtX = transMatrix.dot(designMatrix)  #(X^T X)\n",
    "\n",
    "    calcReg = calcXtX + (lamda * identityMatrix)  #(X^T X + lamda*identity) - Regularisation\n",
    "    calcInverse = np.linalg.inv(calcReg) #(X^T X + lamda*identity)^(-1)\n",
    "\n",
    "    calcXtY = (transMatrix.dot(trainY)) #X^T y\n",
    "    thetaVector = calcInverse.dot(calcXtY) # theta = (X^T X + lamda*identity)^(-1) X^T y\n",
    "\n",
    "    return thetaVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee22e64",
   "metadata": {},
   "source": [
    "### Perform closed-form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac73ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Call function\n",
    "\n",
    "# Lambda is a hyperparameter that is used for regularisation\n",
    "# Lambda was tested at a few different values but had a very minimal impact on the accuracy of the model.\n",
    "lamda = 0.1    \n",
    "thetaVector = createOptimalTheta(lamda)\n",
    "\n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(thetaVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bae66",
   "metadata": {},
   "source": [
    "### Calculate predicted y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61997158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "predictedY = calculateY(designMatrix, thetaVector)\n",
    "\n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(predictedY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7bf61",
   "metadata": {},
   "source": [
    "### Print Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d823b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Hyper Parameters:\n",
      "\n",
      "lambda is: 0.1\n",
      "===========================\n",
      "\n",
      "===========================\n",
      "Confusion Matrix\n",
      "\n",
      "Class\t\tLegitimate\tPhishing\n",
      "Legitimate\t3137\t\t264\n",
      "Phishing\t260\t\t3217\n",
      "\n",
      "=========================\n",
      "\n",
      "===========================\n",
      "Accuracy of: 92.38151 %\n",
      "===========================\n",
      "\n",
      "\n",
      "===========================\n",
      "Number of outiers = 10\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================\")\n",
    "print(\"Hyper Parameters:\\n\")\n",
    "\n",
    "# Call functions\n",
    "quad1, quad2, quad3, quad4, outliers = getConfusionMatrix(predictedY, trainY)\n",
    "printConfusionMatrix(quad1, quad2, quad3, quad4, \"lambda\", lamda)\n",
    "\n",
    "print(\"===========================\")\n",
    "print(\"Number of outiers = \" + str(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2854cf",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec4389",
   "metadata": {},
   "source": [
    "### Function to calculate gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170505cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent Function\n",
    "def gradientDescent(designMat, a_val, stoppingVal, y_set):\n",
    "    \n",
    "    # Initialise variables\n",
    "    amountOfThetas = designMat.shape[1]\n",
    "    newTheta = np.repeat(0.5, amountOfThetas)\n",
    "    oldTheta = np.repeat(99999, amountOfThetas)\n",
    "    \n",
    "    # If the x values and the y values have a different number of rows\n",
    "    if (len(designMat) != len(y_set)):\n",
    "        print(\"The x values and the y values have different lengths\")\n",
    "        return []\n",
    "    \n",
    "    # Repeat until convergence\n",
    "    while (np.linalg.norm(newTheta - oldTheta,2) > stoppingVal):\n",
    "        \n",
    "        # Calculate predicted y values with new theta\n",
    "        for i in range(len(designMat)):\n",
    "            \n",
    "            oldTheta = newTheta\n",
    "            \n",
    "            y = newTheta[0]\n",
    "            \n",
    "            for j in range(1, len(designMat[i])): \n",
    "\n",
    "                y = y + designMat[i][j] * newTheta[j]\n",
    "        \n",
    "               \n",
    "            \n",
    "                # FORMULA: theta = theta - a(predictedY - trueY)x\n",
    "                var1 = a * (y - y_set[y_set.index[j]])  # a(predictedY - trueY)\n",
    "                var = np.multiply(designMat[i], np.float64(var1))  # a(predictedY - trueY)x\n",
    "                newTheta = newTheta - var  # theta = theta - a(predictedY - trueY)x\n",
    "\n",
    "            # Converged\n",
    "            if (np.linalg.norm(newTheta - oldTheta,2) > stoppingVal):\n",
    "                break  \n",
    "        \n",
    "    \n",
    "    return newTheta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe557a",
   "metadata": {},
   "source": [
    "### Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a59e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter value (alpha) and (stoppingVal - used for the convergence)\n",
    "a = 0.00001\n",
    "stoppingVal = 0.001\n",
    "\n",
    "# Call function\n",
    "gradientTheta = gradientDescent(designMatrix, a, stoppingVal, trainY)\n",
    "\n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(gradientTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a040f3ed",
   "metadata": {},
   "source": [
    "### Calculate predicted y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f118d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "newY = calculateY(designMatrix, gradientTheta)\n",
    "\n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(newY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484c7e3",
   "metadata": {},
   "source": [
    "### Print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a8205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Hyper Parameters:\n",
      "\n",
      "stoppingval is: 0.001\n",
      "alpha is: 1e-05\n",
      "===========================\n",
      "\n",
      "===========================\n",
      "Confusion Matrix\n",
      "\n",
      "Class\t\tLegitimate\tPhishing\n",
      "Legitimate\t2736\t\t668\n",
      "Phishing\t2609\t\t875\n",
      "\n",
      "=========================\n",
      "\n",
      "===========================\n",
      "Accuracy of: 52.42451 %\n",
      "===========================\n",
      "\n",
      "\n",
      "===========================\n",
      "Number of outiers = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================\")\n",
    "print(\"Hyper Parameters:\\n\")\n",
    "print(\"stoppingval is: \" + str(stoppingVal))\n",
    "\n",
    "quad1, quad2, quad3, quad4, outliers = getConfusionMatrix(newY, trainY)\n",
    "printConfusionMatrix(quad1, quad2, quad3, quad4, \"alpha\", a)\n",
    "\n",
    "print(\"===========================\")\n",
    "print(\"Number of outiers = \" + str(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617241a",
   "metadata": {},
   "source": [
    "# VALIDATION DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6761d67",
   "metadata": {},
   "source": [
    "### Closed-Form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e879d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get design matrix\n",
    "designMatVal = createDesignMatrix(valX)\n",
    "\n",
    "# Store different hyper parameters for lambda to find the highest accuracy\n",
    "lamda = [0.001, 0.05, 0.1, 2, 5]\n",
    "accuracyVec = np.array([0, 0, 0, 0, 0])\n",
    "\n",
    "for lambdaIndex in range(len(lamda)):\n",
    "    \n",
    "    # Create theta vector\n",
    "    thetaValidation = createOptimalTheta(lamda[lambdaIndex])\n",
    "    \n",
    "    # Calculate predicted y values\n",
    "    predictedValY = calculateY(designMatVal, thetaValidation)\n",
    "    \n",
    "    # Get confusion matrix data to calculate accuracy\n",
    "    quad1, quad2, quad3, quad4, outliers = getConfusionMatrix(predictedValY, valY)\n",
    "    # Calculate accuracy and store it\n",
    "    accuracy = (quad1 + quad4)/(quad1 + quad2 + quad3 + quad4)\n",
    "    accuracyVec[lambdaIndex] = accuracy\n",
    "    \n",
    "# Find index of highest accuracy and determine best hyper parameter\n",
    "maxAccuracyIndex = np.argmax(accuracyVec, axis=0)\n",
    "\n",
    "# Set optimalLambda to best optimal lambda\n",
    "optimalLambda = lamda[maxAccuracyIndex]\n",
    "    \n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(optimalLambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86d687",
   "metadata": {},
   "source": [
    "### Gradient Decsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7756083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 26min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get design matrix\n",
    "designMatVal = createDesignMatrix(valX)\n",
    "\n",
    "# Store different hyper parameters for alpha and the stopping value to find the highest accuracy\n",
    "# Because there are two hyper parameters, we use a double for loop is so that every alpha \n",
    "# parameter is tested with every stopping value parameter. \n",
    "# There are 4 values in each list, so it runs 16 times to find the accuracy - this takes a loooonnggg time.\n",
    "alpha = [0.00001, 0.01] #, 1, 5\n",
    "stoppingVec = [0.0001, 0.1] #, 1, 5\n",
    "accuracyVec = np.zeros((len(alpha), len(stoppingVec)))\n",
    "\n",
    "# for each alpha parameter\n",
    "for alphaIndex in range(len(alpha)):\n",
    "    \n",
    "    # for each stopping value parameter\n",
    "    for stoppingIndex in range(len(stoppingVec)):\n",
    "    \n",
    "        # Create theta vector\n",
    "        thetaValidation = gradientDescent(designMatVal, alpha[alphaIndex], stoppingVec[stoppingIndex], valY)\n",
    "\n",
    "        # Calculate predicted y values\n",
    "        predictedValY = calculateY(designMatVal, thetaValidation)\n",
    "\n",
    "        # Get confusion matrix data to calculate accuracy\n",
    "        quad1, quad2, quad3, quad4, outliers = getConfusionMatrix(predictedValY, valY)\n",
    "        # Calculate accuracy and store it\n",
    "        accuracy = (quad1 + quad4)/(quad1 + quad2 + quad3 + quad4)\n",
    "        accuracyVec[alphaIndex][stoppingIndex] = accuracy\n",
    "    \n",
    "    \n",
    "# Find value and index of highest accuracy and determine best hyper parameters\n",
    "maxAccuracy = np.max(accuracyVec)\n",
    "indexes = np.where(accuracyVec == maxAccuracy)\n",
    "\n",
    "# Set optimalAlpha and optimalStopping to best optimal values\n",
    "optimalAlpha = alpha[indexes[0][0]]\n",
    "optimalStopping = stoppingVec[indexes[1][0]]\n",
    "    \n",
    "# :) Please uncomment to see the print statement (if desired):\n",
    "#print(optimalAlpha)\n",
    "#print(optimalStopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdd354",
   "metadata": {},
   "source": [
    "# TESTING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637b0a4",
   "metadata": {},
   "source": [
    "### Closed-Form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a18bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Hyper Parameters:\n",
      "\n",
      "lambda is: 0.001\n",
      "===========================\n",
      "\n",
      "===========================\n",
      "Confusion Matrix\n",
      "\n",
      "Class\t\tLegitimate\tPhishing\n",
      "Legitimate\t1072\t\t79\n",
      "Phishing\t73\t\t1068\n",
      "\n",
      "=========================\n",
      "\n",
      "===========================\n",
      "Accuracy of: 93.36824 %\n",
      "===========================\n",
      "\n",
      "\n",
      "===========================\n",
      "Number of outiers = 5\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get design matrix\n",
    "designMatTest = createDesignMatrix(testX)\n",
    "\n",
    "# Calculate predicted y values\n",
    "predictedTestY = calculateY(designMatTest, thetaVector)\n",
    "\n",
    "print(\"===========================\")\n",
    "print(\"Hyper Parameters:\\n\")\n",
    "    \n",
    "# Get confusion matrix and print it\n",
    "quad1, quad2, quad3, quad4, outliers = getConfusionMatrix(predictedTestY, testY)\n",
    "printConfusionMatrix(quad1, quad2, quad3, quad4, \"lambda\", optimalLambda)\n",
    "\n",
    "print(\"===========================\")\n",
    "print(\"Number of outiers = \" + str(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa4a7e",
   "metadata": {},
   "source": [
    "### Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27d1bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Hyper Parameters:\n",
      "\n",
      "stoppingval is: 0.001\n",
      "alpha is: 1e-05\n",
      "===========================\n",
      "\n",
      "===========================\n",
      "Confusion Matrix\n",
      "\n",
      "Class\t\tLegitimate\tPhishing\n",
      "Legitimate\t935\t\t217\n",
      "Phishing\t870\t\t275\n",
      "\n",
      "=========================\n",
      "\n",
      "===========================\n",
      "Accuracy of: 52.67741 %\n",
      "===========================\n",
      "\n",
      "\n",
      "===========================\n",
      "Number of outiers = 0\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get design matrix\n",
    "designMatTest = createDesignMatrix(testX)\n",
    "\n",
    "# Calculate predicted y values\n",
    "predictedTestY = calculateY(designMatTest, gradientTheta)\n",
    "\n",
    "# Get and print confusion matrix\n",
    "print(\"===========================\")\n",
    "print(\"Hyper Parameters:\\n\")\n",
    "print(\"stoppingval is: \" + str(stoppingVal))\n",
    "\n",
    "quad1, quad2, quad3, quad4, outliers = getConfusionMatrix(predictedTestY, testY)\n",
    "printConfusionMatrix(quad1, quad2, quad3, quad4, \"alpha\", a)\n",
    "\n",
    "print(\"===========================\")\n",
    "print(\"Number of outiers = \" + str(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e7fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
