{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors\n",
    "# ----------------------------------------\n",
    "\n",
    "## Kiara Gabriel             -    2161334\n",
    "\n",
    "## Phola Bavuma          -    1848739\n",
    "\n",
    "## Shravan Singh         -    2173638\n",
    "\n",
    "## Arneev Singh          -    2180393\n",
    "\n",
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "tabSpace = 30\n",
    "learningRate = 0.1\n",
    "\n",
    "\n",
    "#NOTE: You can adjust this value to display the amount of floating points\n",
    "floatingDigits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function - Prints Question\n",
    "def printQues(questionNumber):\n",
    "    ans = \"Question (\" + questionNumber + \")\"\n",
    "    \n",
    "    hashes = \"\"\n",
    "    for i in range(len(ans)):\n",
    "        hashes += '='\n",
    "    \n",
    "    print(ans)\n",
    "    print(hashes)\n",
    "    \n",
    "def printConfusionMatrix(correct0, incorrect0,correct1,incorrect1):\n",
    "    amountDataPoints = correct0 + incorrect0 + correct1 +incorrect1\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"====================\")\n",
    "    print(\"Class\\t0\\t1\")\n",
    "    print(\"0\\t\"+str(correct0)+\"\\t\"+str(incorrect0))\n",
    "    print(\"1\\t\"+str(incorrect1)+\"\\t\"+str(correct1))\n",
    "    print(\"\\nAccuracy is \"+ str(((correct0 + correct1)/(amountDataPoints))*100) + \"%\")\n",
    "    print(\"====================\\n\")\n",
    "    \n",
    "    return (correct0 + correct1)/amountDataPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid Function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def derivSigmoid(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "def norm2(new,old):\n",
    "    fsum = 0.0\n",
    "    \n",
    "    newLst = new[0]\n",
    "    oldLst = old[0]\n",
    "    \n",
    "    for i in range(len(newLst)):\n",
    "        for j in range(len(newLst[i])):\n",
    "            fsum += (newLst[i][j] - oldLst[i][j])**2\n",
    "    \n",
    "    newLst = new[1]\n",
    "    oldLst = old[1]\n",
    "    \n",
    "    for i in range(len(newLst)):\n",
    "        for j in range(len(newLst)):\n",
    "            fsum += (newLst[i][j] - oldLst[i][j])**2\n",
    "    \n",
    "    return fsum ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dot Product\n",
    "def myDot(inputVec,thetaMat):\n",
    "    ansLst = []\n",
    "    \n",
    "    for thetaLst in thetaMat:\n",
    "        isum = 0\n",
    "        \n",
    "        for i in range(len(thetaLst)):\n",
    "            isum += thetaLst[i] * inputVec[i]\n",
    "        \n",
    "        ansLst.append(isum)\n",
    "        \n",
    "    return ansLst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.value = 1.0\n",
    "        self.weights = []\n",
    "        self.error = 0.0\n",
    "    \n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def addWeight(self, weight):\n",
    "        self.weights.append(weight)\n",
    "        \n",
    "    def getWeight(self, index):\n",
    "        return self.weights[index]\n",
    "    \n",
    "    def setError(self, errorVal):\n",
    "        self.error = errorVal\n",
    "        \n",
    "    def getError(self):\n",
    "        return self.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, size):\n",
    "        self.nodes = []\n",
    "        \n",
    "        for i in range(size):\n",
    "            self.nodes.append(Node())\n",
    "            \n",
    "    def __str__(self):\n",
    "        lst = []\n",
    "        \n",
    "        for i in range(self.getSize()):\n",
    "            lst.append(self.nodes[i].value)\n",
    "            \n",
    "        return str(lst)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.nodes[index]\n",
    "        \n",
    "    def getSize(self):\n",
    "        return len(self.nodes)\n",
    "        \n",
    "    def setNodeValue(self, index, value):\n",
    "        self.nodes[index].setValue(value)\n",
    "        \n",
    "    def setNodeError(self, index, error):\n",
    "        self.nodes[index].setError(error)\n",
    "    \n",
    "    def addNodeWeight(self, index, weight):\n",
    "        self.nodes[index].addWeight(weight)\n",
    "    \n",
    "    def addNode(self, node):\n",
    "        self.nodes.append(node)\n",
    "        \n",
    "    def updateNode(self, index, value):\n",
    "        self.nodes[index].value = value\n",
    "    \n",
    "    def getNodeValue(self,index):\n",
    "        return self.nodes[index].value\n",
    "    \n",
    "    def getNodeWeights(self, index):\n",
    "        return self.nodes[index].weights\n",
    "    \n",
    "    def getNodesValue(self):\n",
    "        lst = []\n",
    "        for node in self.nodes:\n",
    "            lst.append(node.value)\n",
    "        \n",
    "        return lst\n",
    "    \n",
    "    def getNodesWeight(self):\n",
    "        lst = []\n",
    "        \n",
    "        for i in range(len(self.nodes[0].weights)):\n",
    "            lst.append([])\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            weightIndex = 0\n",
    "            for weight in node.weights:\n",
    "                lst[weightIndex].append(weight)\n",
    "                weightIndex += 1\n",
    "                \n",
    "        return lst\n",
    "    \n",
    "    def getAmountWeightPerNode(self):\n",
    "        return len(self.nodes[0].weights)\n",
    "    \n",
    "    def clearWeights(self):\n",
    "        for node in self.nodes:\n",
    "            node.weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, nodeLst):\n",
    "        \n",
    "        self.nodeLst = nodeLst\n",
    "        self.layers = []\n",
    "        \n",
    "        for numberNodes in nodeLst:\n",
    "            self.layers.append(Layer(numberNodes))\n",
    "            \n",
    "        \n",
    "        self.amountLayers = len(nodeLst)\n",
    "    \n",
    "    def setInputLayer(self, inputValues):\n",
    "        \n",
    "        #Making sure they fit\n",
    "        if (len(inputValues) != self.layers[0].getSize() - 1):\n",
    "            print(\"Input Values cannot fit into Input Layer\")\n",
    "            print(\"Input Values is:\")\n",
    "            print(inputValues)\n",
    "            print(\"Input Layer is:\")\n",
    "            print(self.layers[0])\n",
    "            print(\"Remember there is no input value for the first(bias) node\")\n",
    "            return\n",
    "        \n",
    "        self.inputValues = inputValues\n",
    "        \n",
    "        #Setting Bias Node = 1\n",
    "        self.layers[0].setNodeValue(0,1)\n",
    "        \n",
    "        #Setting Other Nodes to Input Values\n",
    "        for i in range(len(inputValues)):\n",
    "            self.layers[0].setNodeValue(i+1,inputValues[i])\n",
    "            \n",
    "    \n",
    "    def printNetwork(self,showWeights=False):\n",
    "        \n",
    "        #get maxAmountNodes of layers\n",
    "        maxAmountNodes = 0  \n",
    "        for layer in self.layers:\n",
    "            size = layer.getSize()\n",
    "            if (size > maxAmountNodes):\n",
    "                maxAmountNodes = size\n",
    "        \n",
    "        #Add empty list for maxAmountNodes\n",
    "        valueLst = []\n",
    "        weightsLst = []\n",
    "        for i in range(maxAmountNodes):\n",
    "            valueLst.append([])\n",
    "            weightsLst.append([])\n",
    "        \n",
    "        #Adding all nodes to layerLst\n",
    "        for i in range(len(self.layers)):\n",
    "            for j in range(self.layers[i].getSize()):\n",
    "                valueLst[j].append(self.layers[i].getNodeValue(j))\n",
    "                weightsLst[j].append(self.layers[i].getNodeWeights(j))\n",
    "                \n",
    "                \n",
    "        #Printing out layerLst\n",
    "        for row in valueLst:\n",
    "            sLine = \"\"\n",
    "            for val in row:\n",
    "                sLine += str((\"{:.\"+str(floatingDigits)+\"}\").format(float(val))) + '\\t'\n",
    "            \n",
    "            print(sLine)\n",
    "            \n",
    "        if (showWeights):\n",
    "            print()\n",
    "            for row in weightsLst:\n",
    "                sLine = \"\"\n",
    "                for val in row:\n",
    "                    if (type(val) == list):\n",
    "                        tempLst = []\n",
    "                        for e in val:\n",
    "                            tempLst.append((\"{:.\"+str(floatingDigits)+\"}\").format(float(e)))\n",
    "                        \n",
    "                        sLine += str(tempLst) + '\\t'\n",
    "                        continue\n",
    "                    sLine += str((\"{:.\"+str(floatingDigits)+\"}\").format(float(val))) + '\\t'\n",
    "\n",
    "                print(sLine.expandtabs(tabSpace))\n",
    "            \n",
    "        \n",
    "    def setWeights(self, weights):\n",
    "        self.orignalWeights = weights\n",
    "        #For each layer in weight\n",
    "        for layerIndex in range(len(weights)):\n",
    "            thetaMat = weights[layerIndex]\n",
    "            self.layers[layerIndex].clearWeights()\n",
    "            \n",
    "            #For each thetaLst in thetaMat (this is for one layer)\n",
    "            for thetaLst in thetaMat:\n",
    "                \n",
    "                for nodeIndex in range(len(thetaLst)):\n",
    "                    self.layers[layerIndex].addNodeWeight(nodeIndex, thetaLst[nodeIndex])\n",
    "        \n",
    "\n",
    "    def setActivationFunction(self, activationFunction):\n",
    "        self.activationFunction = activationFunction\n",
    "                \n",
    "        \n",
    "    def forwardPropagation(self):\n",
    "        #Getting weights of node\n",
    "        \n",
    "        #For each layer\n",
    "        for layerIndex in range(len(self.layers)):\n",
    "            #If last layer then continue\n",
    "            if (layerIndex == len(self.layers) - 1):\n",
    "                continue\n",
    "                \n",
    "            layer = self.layers[layerIndex]\n",
    "            nextLayer = self.layers[layerIndex + 1]\n",
    "            \n",
    "            nodeVals = layer.getNodesValue()\n",
    "            nodeWeights = layer.getNodesWeight()\n",
    "\n",
    "            dotProduct = myDot(nodeVals,nodeWeights)\n",
    "            \n",
    "            if (type(dotProduct) == float):\n",
    "                nextLayer.setNodeValue(1,self.activationFunction(dotProduct))\n",
    "                return\n",
    "            \n",
    "            for i in range(len(dotProduct)):\n",
    "                if (layerIndex == len(self.layers) -2):\n",
    "                    nextLayer.setNodeValue(i,self.activationFunction(dotProduct[i]))\n",
    "                    return\n",
    "                \n",
    "                nextLayer.setNodeValue(i+1,self.activationFunction(dotProduct[i]))\n",
    "                \n",
    "        outputLayer = self.layers[len(self.layers) -1]\n",
    "        outputNodeValue = outputLayer.getNodeValue(0)\n",
    "        \n",
    "        outputLayer.setNodeValue(0,self.activationFunction(outputNodeValue))\n",
    "            \n",
    "    def getOutput(self):\n",
    "        return (self.layers[len(self.layers)-1].getNodeValue(0))\n",
    "            \n",
    "    def resetNetwork(self):\n",
    "        for layer in self.layers:\n",
    "            for node in layer.nodes:\n",
    "                node.value = 1\n",
    "                node.weights = []\n",
    "        \n",
    "        \n",
    "    def setActualOutputs(yLst):\n",
    "        self.actualOutputs = yLst\n",
    "    \n",
    "    def backwardPropagation(self, yActual, learningRate=0.1):\n",
    "        amountLayers = len(self.layers)\n",
    "        \n",
    "        #Updating the output layer's last hidden layer\n",
    "        yCalc = self.getOutput()\n",
    "        yActual = yActual\n",
    "\n",
    "        lastNodeVal = self.layers[amountLayers - 1].getNodeValue(0)\n",
    "\n",
    "        #Calculating error of output\n",
    "        errorOutput = (yActual - yCalc)*derivSigmoid(lastNodeVal)\n",
    "        \n",
    "        #Setting output node error\n",
    "        self.layers[amountLayers - 1].setNodeError(0,errorOutput)\n",
    "\n",
    "        #Updating previous layers weights\n",
    "        for prevNodeIndex, prevNode in enumerate(self.layers[amountLayers - 2].nodes):\n",
    "            \n",
    "            #DeltaW and updating the weight\n",
    "            prevNode.weights[0] += learningRate * errorOutput * prevNode.value\n",
    "            \n",
    "    \n",
    "        #End of Updating the output layer's last hidden layer  \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Updating all previous hidden layers\n",
    "        lastHiddenLayerIndex = amountLayers - 2\n",
    "        \n",
    "        #From second last hidden layer to first hidden layer\n",
    "        for layerIndex in range(lastHiddenLayerIndex,0,-1):\n",
    "            currLayer = self.layers[layerIndex]\n",
    "            nextLayer = self.layers[layerIndex + 1]\n",
    "            prevLayer = self.layers[layerIndex - 1]\n",
    "            \n",
    "            #For every node in this layer\n",
    "            for currNodeIndex, currNode in enumerate(currLayer.nodes):\n",
    "                if (currNodeIndex == 0):\n",
    "                    continue\n",
    "                \n",
    "                #Get currNodeError\n",
    "                currNodeError = 0.0\n",
    "                \n",
    "                #Getting error for currNode from each next node\n",
    "                for nextNodeIndex, nextNode in enumerate(nextLayer):\n",
    "                    currNodeError += nextNode.error * currNode.weights[nextNodeIndex]\n",
    "                    \n",
    "                #Getting average error for node\n",
    "                currNodeError /= len(currLayer.nodes)\n",
    "                \n",
    "                currNode.setError(currNodeError)\n",
    "                #Get currNodeError - Done\n",
    "                \n",
    "                #===============================\n",
    "                \n",
    "                #Updating weights of prevLayer\n",
    "                \n",
    "                for prevNode in prevLayer.nodes:\n",
    "                    #Updating Weights of the non bias nodes\n",
    "                    prevNode.weights[currNodeIndex-1] += learningRate * currNodeError * prevNode.value\n",
    "                    \n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "        \n",
    "    def getWeights(self):\n",
    "        weights = []\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            weights.append(layer.getNodesWeight())\n",
    "        \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Print Neural Network\n",
    "\n",
    "def printNeuralWithHelper(inputVec, neuralNetwork, questionNumber, func, theta):\n",
    "    neuralNetwork.resetNetwork()\n",
    "    neuralNetwork.setInputLayer(inputVec)\n",
    "    \n",
    "    printQues(questionNumber)\n",
    "    \n",
    "    neuralNetwork.setWeights(theta)\n",
    "    neuralNetwork.setActivationFunction(func)\n",
    "\n",
    "    print(\"Before Forward Propogation\")\n",
    "    neuralNetwork.printNetwork(False)\n",
    "    print()\n",
    "\n",
    "    neuralNetwork.forwardPropagation()\n",
    "\n",
    "    print(\"Forward Propogation\")\n",
    "    neuralNetwork.printNetwork(False)\n",
    "    print()\n",
    "\n",
    "    print(\"Output\")\n",
    "    print(neuralNetwork.getOutput())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "amountNodeLst = [4,3,1]\n",
    "q1NN = NeuralNetwork(amountNodeLst)\n",
    "\n",
    "thetaMat = [\n",
    "    [\n",
    "        [1,-1,0.5,1]\n",
    "        ,\n",
    "        [2,-2,1,-1]\n",
    "    ]\n",
    "    ,\n",
    "    [\n",
    "        [-1,2,1]\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (1a-i)\n",
      "===============\n",
      "Before Forward Propogation\n",
      "1.0\t1.0\t1.0\t\n",
      "0.0\t1.0\t\n",
      "3.0\t1.0\t\n",
      "-1.0\t\n",
      "\n",
      "Forward Propogation\n",
      "1.0\t1.0\t0.83654\t\n",
      "0.0\t0.81757\t\n",
      "3.0\t0.99753\t\n",
      "-1.0\t\n",
      "\n",
      "Output\n",
      "0.8365359392688426\n"
     ]
    }
   ],
   "source": [
    "inputVal1 = [0,3,-1]\n",
    "\n",
    "printNeuralWithHelper(inputVal1, q1NN, \"1a-i\",sigmoid, thetaMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (1a-ii)\n",
      "================\n",
      "Before Forward Propogation\n",
      "1.0\t1.0\t1.0\t\n",
      "1.0\t1.0\t\n",
      "2.0\t1.0\t\n",
      "1.0\t\n",
      "\n",
      "Forward Propogation\n",
      "1.0\t1.0\t0.81648\t\n",
      "1.0\t0.8808\t\n",
      "2.0\t0.73106\t\n",
      "1.0\t\n",
      "\n",
      "Output\n",
      "0.8164760997195802\n"
     ]
    }
   ],
   "source": [
    "inputVal2 = [1,2,1]\n",
    "\n",
    "printNeuralWithHelper(inputVal2, q1NN, \"1a-ii\",sigmoid, thetaMat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (1a-iii)\n",
      "=================\n",
      "Before Forward Propogation\n",
      "1.0\t1.0\t1.0\t\n",
      "-1.0\t1.0\t\n",
      "1.0\t1.0\t\n",
      "2.0\t\n",
      "\n",
      "Forward Propogation\n",
      "1.0\t1.0\t0.87332\t\n",
      "-1.0\t0.98901\t\n",
      "1.0\t0.95257\t\n",
      "2.0\t\n",
      "\n",
      "Output\n",
      "0.8733158426540304\n"
     ]
    }
   ],
   "source": [
    "inputVal3 = [-1,1,2]\n",
    "\n",
    "printNeuralWithHelper(inputVal3, q1NN, \"1a-iii\",sigmoid, thetaMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (1b)\n",
      "=============\n",
      "\n",
      "1.0\t1.0\t0.83654\t\n",
      "0.0\t0.81757\t\n",
      "3.0\t0.99753\t\n",
      "-1.0\t\n",
      "\n",
      "['0.98832', '1.9942']         ['-1.0176']                   []                            \n",
      "['-1.0', '-2.0']              ['1.9856']                    \n",
      "['0.46497', '0.98267']        ['0.9824']                    \n",
      "['1.0117', '-0.99422']        \n",
      "\n",
      "Input Layer Weights           Hidden Layer Weights          Output Layer Weights\n",
      "\n",
      "1.0\t1.0\t0.81648\t\n",
      "1.0\t0.8808\t\n",
      "2.0\t0.73106\t\n",
      "1.0\t\n",
      "\n",
      "['1.0026', '2.0013']          ['-0.9961']                   []                            \n",
      "['-0.99739', '-1.9987']       ['2.0034']                    \n",
      "['0.50521', '1.0026']         ['1.0029']                    \n",
      "['1.0026', '-0.9987']         \n",
      "\n",
      "Input Layer Weights           Hidden Layer Weights          Output Layer Weights\n",
      "\n",
      "1.0\t1.0\t0.87332\t\n",
      "-1.0\t0.98901\t\n",
      "1.0\t0.95257\t\n",
      "2.0\t\n",
      "\n",
      "['0.98801', '1.9941']         ['-1.0181']                   []                            \n",
      "['-0.98801', '-1.9941']       ['1.9821']                    \n",
      "['0.48801', '0.99406']        ['0.98271']                   \n",
      "['0.97602', '-1.0119']        \n",
      "\n",
      "Input Layer Weights           Hidden Layer Weights          Output Layer Weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 1b\n",
    "\n",
    "#Intializing and reseting the neural network\n",
    "def printWithBackprop(neuralNet, inputVec, thetaMat, func, learningRate, targetVal):\n",
    "    neuralNet.resetNetwork()\n",
    "    neuralNet.setInputLayer(inputVec)\n",
    "    neuralNet.setWeights(thetaMat)\n",
    "    neuralNet.setActivationFunction(func)\n",
    "\n",
    "    neuralNet.forwardPropagation()\n",
    "    neuralNet.backwardPropagation(targetVal,learningRate)\n",
    "\n",
    "    neuralNet.printNetwork(True)\n",
    "    print()\n",
    "    \n",
    "    print(\"Input Layer Weights\\tHidden Layer Weights\\tOutput Layer Weights\".expandtabs(tabSpace))\n",
    "    print()\n",
    "\n",
    "printQues(\"1b\")\n",
    "print()\n",
    "\n",
    "printWithBackprop(q1NN, [0,3,-1], thetaMat, sigmoid, learningRate, 0)\n",
    "printWithBackprop(q1NN, [1,2,1], thetaMat, sigmoid, learningRate, 1)\n",
    "printWithBackprop(q1NN, [-1,1,2], thetaMat, sigmoid, learningRate, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (2a)\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "#Question 2(a)\n",
    "\n",
    "def f(x):\n",
    "    return (x**2)*(math.sin(2*math.pi*x))+0.7\n",
    "\n",
    "printQues(\"2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(b) & 2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (2b & 2c)\n",
      "==================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question 2(b) and 2(c)\n",
    "\n",
    "def dataPoints(class0_points_x, class0_points_y, class1_points_x, class1_points_y):\n",
    "    \n",
    "    dataset = np.random.uniform(0,1,size=(100,2))\n",
    "    classes = np.zeros(100)\n",
    "    class0 = [class0_points_x,class0_points_y]\n",
    "\n",
    "    class1 = [class1_points_x,class1_points_y]\n",
    "\n",
    "    for i in range(100):\n",
    "        if(f(dataset[i][0])> (dataset[i][1])):\n",
    "            classes[i] = 0\n",
    "            class0_points_x.append(dataset[i][0])\n",
    "            class0_points_y.append(dataset[i][1])\n",
    "        else:\n",
    "            classes[i] = 1\n",
    "            class1_points_x.append(dataset[i][0])\n",
    "            class1_points_y.append(dataset[i][1])\n",
    "\n",
    "\n",
    "printQues(\"2b & 2c\")\n",
    "            \n",
    "class0_points_x = []\n",
    "class0_points_y = []\n",
    "\n",
    "class1_points_x = []\n",
    "class1_points_y = []\n",
    "    \n",
    "dataPoints(class0_points_x, class0_points_y, class1_points_x, class1_points_y)\n",
    "\n",
    "plt.scatter(class0_points_x,class0_points_y)\n",
    "plt.scatter(class1_points_x,class1_points_y)\n",
    "plt.axis('equal')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (3a)\n",
      "=============\n",
      "\n",
      "[0.60866249 0.40236483 0.96035765]\n",
      "[0.67038233 0.59186    0.68278269]\n",
      "[0.37985828 0.26180265 0.76647377]\n",
      "[0.95177568 0.25946325 0.22133179 0.25813797]\n",
      " \n",
      "[[array([0.60866249, 0.40236483, 0.96035765]), array([0.67038233, 0.59186   , 0.68278269]), array([0.37985828, 0.26180265, 0.76647377])], [array([0.95177568, 0.25946325, 0.22133179, 0.25813797])]]\n"
     ]
    }
   ],
   "source": [
    "## Question 3a\n",
    "def check(thetas):\n",
    "    for i in range(len(thetas) -1):\n",
    "        for a in range(len(thetas) ):\n",
    "            if(i == a):\n",
    "                continue\n",
    "            x = thetas[i]\n",
    "            y = thetas[a]\n",
    "            if(x == y):\n",
    "                y = np.random.uniform(0,1)\n",
    "                thetas[a] = y\n",
    "        \n",
    "\n",
    "def createTheataMatrix(N1firstThetas, N2firstThetas, N3firstThetas, SecondLayerThetas):\n",
    "    thetaMatrix = [\n",
    "        [\n",
    "            N1firstThetas\n",
    "            ,\n",
    "            N2firstThetas\n",
    "            ,\n",
    "            N3firstThetas\n",
    "        ]\n",
    "        ,\n",
    "        [\n",
    "            SecondLayerThetas\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return thetaMatrix\n",
    "\n",
    "def getThetas(nodelist):\n",
    "        \n",
    "    N1firstThetas = np.random.uniform(0,1,size=3)\n",
    "    check(N1firstThetas)\n",
    "\n",
    "    N2firstThetas = np.random.uniform(0,1,size=3)\n",
    "    check(N2firstThetas)\n",
    "\n",
    "    N3firstThetas = np.random.uniform(0,1,size=3)\n",
    "    check(N3firstThetas)\n",
    "\n",
    "    SecondLayerThetas = np.random.uniform(0,1,size = 4)\n",
    "    check(SecondLayerThetas)\n",
    "    \n",
    "    thetaMatrix = createTheataMatrix(N1firstThetas, N2firstThetas, N3firstThetas, SecondLayerThetas)\n",
    "    \n",
    "    return thetaMatrix\n",
    "\n",
    "\n",
    "nodelist = [3,4,1]\n",
    "q3NN =  NeuralNetwork(nodelist)\n",
    "\n",
    "thetaMatrix = getThetas(nodelist)\n",
    "N1firstThetas = thetaMatrix[0][0]\n",
    "N2firstThetas = thetaMatrix[0][1]\n",
    "N3firstThetas = thetaMatrix[0][2]\n",
    "SecondLayerThetas = thetaMatrix[1][0]\n",
    "\n",
    "printQues(\"3a\")\n",
    "print()\n",
    "\n",
    "print(N1firstThetas)\n",
    "print(N2firstThetas)\n",
    "print(N3firstThetas)\n",
    "print(SecondLayerThetas)\n",
    "print(\" \")\n",
    "\n",
    "print(thetaMatrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (3b)\n",
      "=============\n",
      "\n",
      "Class 0\n",
      "=======\n",
      "\n",
      "[0.8168214824845813, 0.8110904849044421, 0.813288002232884, 0.8165694260678047, 0.8142486168622518, 0.8150505840704027, 0.8181718310594424, 0.8192420375278714, 0.8133182357418478, 0.8137371643051161, 0.8116401429388173, 0.8202578525626865, 0.8137553354836955, 0.816086119286936, 0.8177481617309316, 0.8133240317184244, 0.8154712850986877, 0.820703173527292, 0.8169472699861617, 0.8139256584397443, 0.8136024804868516, 0.8071127287564761, 0.8135976956101255, 0.8177088089171728, 0.8168009430389233, 0.811362418373524, 0.8165838279602748, 0.816545503996455, 0.821318918054548, 0.815415225167078, 0.8146094991192604, 0.8194235409199735, 0.8112124462145419, 0.8116444265224952, 0.8197276781055264, 0.8202172072788373, 0.8134537212571047, 0.8083944822905155, 0.8123687604308786, 0.8093981837098122, 0.8096625584322572, 0.8163122926644477, 0.8186821077208507, 0.8165289080003552, 0.8183246467164426, 0.8173307295402349, 0.816150290582041, 0.8175575778482983, 0.8186432286866596, 0.8222826820892286, 0.8162280446296883, 0.8181386711232244, 0.8192076512919297, 0.8193345083385776]\n",
      "\n",
      "\n",
      "Class 1\n",
      "=======\n",
      "\n",
      "[0.8212142724512823, 0.822105337379616, 0.8268415680346717, 0.8249164306016346, 0.8267510302913483, 0.8221170193324979, 0.8226261876529973, 0.8289657596116805, 0.8233165306518302, 0.82182775586969, 0.8176246854658767, 0.823602221949451, 0.8257449708619182, 0.8199491524438878, 0.8201014751139167, 0.8160461130142366, 0.821201129356861, 0.8222768144945013, 0.8221777943173679, 0.8216010716129089, 0.8190643109775202, 0.824888568794316, 0.8229374535271453, 0.8234731271292921, 0.8258738130238398, 0.8250715831465926, 0.8218470712701893, 0.8273774896175448, 0.8244273191558454, 0.821169687651381, 0.8270713281640488, 0.8156078546231501, 0.8196695817256454, 0.8234943020993489, 0.8277987531996845, 0.8263512766465684, 0.819921473577377, 0.8200921870663267, 0.8248388162560604, 0.8190047438841092, 0.8225259376238183, 0.8240028444323566, 0.8213344131935787, 0.8223993392521834, 0.8236065207143262, 0.8171512795090362]\n"
     ]
    }
   ],
   "source": [
    "## Question 3b\n",
    "## doing forward propagation on the NN for both datasets class 0 and class 1\n",
    "def FPonClass0(q3NN, thetaMatrix, class0_points_x, class0_points_y, Output0):\n",
    "    q3NN.setWeights(thetaMatrix)\n",
    "    q3NN.setActivationFunction(sigmoid)\n",
    "    \n",
    "    for i in range(len(class0_points_x)):\n",
    "        x = class0_points_x[i]\n",
    "        y = class0_points_y[i]\n",
    "        arr = [x,y]\n",
    "        q3NN.setInputLayer(arr)\n",
    "        q3NN.forwardPropagation()\n",
    "        Output0.append(q3NN.getOutput()) \n",
    "        \n",
    "    return Output0\n",
    "\n",
    "    \n",
    "def FPonClass1(q3NN, thetaMatrix, class1_points_x, class1_points_y, Output1):\n",
    "    q3NN.setWeights(thetaMatrix)\n",
    "    q3NN.setActivationFunction(sigmoid)\n",
    "\n",
    "    for i in range(len(class1_points_x)):\n",
    "        x = class1_points_x[i]\n",
    "        y = class1_points_y[i]\n",
    "        arr = [x,y]\n",
    "        q3NN.setInputLayer(arr)\n",
    "        q3NN.forwardPropagation()\n",
    "        Output1.append(q3NN.getOutput()) \n",
    "        \n",
    "    return Output1\n",
    "\n",
    "\n",
    "Output0 = []\n",
    "Output1 = []\n",
    "\n",
    "Output0 = FPonClass0(q3NN, thetaMatrix, class0_points_x, class0_points_y, Output0)\n",
    "Output1 = FPonClass1(q3NN, thetaMatrix, class1_points_x, class1_points_y, Output1)\n",
    "\n",
    "printQues(\"3b\")\n",
    "print()\n",
    "print(\"Class 0\")\n",
    "print(\"=======\")\n",
    "print()\n",
    "print(Output0)\n",
    "print()\n",
    "print()\n",
    "print(\"Class 1\")\n",
    "print(\"=======\")\n",
    "print()\n",
    "print(Output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (3c)\n",
      "=============\n",
      "\n",
      "========================\n",
      "Total Errors:\n",
      "100\n",
      "========================\n",
      "\n",
      "[-0.8168214824845813, -0.8110904849044421, -0.813288002232884, -0.8165694260678047, -0.8142486168622518, -0.8150505840704027, -0.8181718310594424, -0.8192420375278714, -0.8133182357418478, -0.8137371643051161, -0.8116401429388173, -0.8202578525626865, -0.8137553354836955, -0.816086119286936, -0.8177481617309316, -0.8133240317184244, -0.8154712850986877, -0.820703173527292, -0.8169472699861617, -0.8139256584397443, -0.8136024804868516, -0.8071127287564761, -0.8135976956101255, -0.8177088089171728, -0.8168009430389233, -0.811362418373524, -0.8165838279602748, -0.816545503996455, -0.821318918054548, -0.815415225167078, -0.8146094991192604, -0.8194235409199735, -0.8112124462145419, -0.8116444265224952, -0.8197276781055264, -0.8202172072788373, -0.8134537212571047, -0.8083944822905155, -0.8123687604308786, -0.8093981837098122, -0.8096625584322572, -0.8163122926644477, -0.8186821077208507, -0.8165289080003552, -0.8183246467164426, -0.8173307295402349, -0.816150290582041, -0.8175575778482983, -0.8186432286866596, -0.8222826820892286, -0.8162280446296883, -0.8181386711232244, -0.8192076512919297, -0.8193345083385776, 0.1787857275487177, 0.177894662620384, 0.17315843196532832, 0.17508356939836545, 0.17324896970865167, 0.17788298066750208, 0.17737381234700267, 0.1710342403883195, 0.1766834693481698, 0.17817224413030996, 0.18237531453412326, 0.17639777805054901, 0.17425502913808177, 0.18005084755611223, 0.17989852488608327, 0.18395388698576343, 0.17879887064313904, 0.1777231855054987, 0.17782220568263207, 0.17839892838709115, 0.1809356890224798, 0.17511143120568395, 0.1770625464728547, 0.1765268728707079, 0.17412618697616022, 0.17492841685340743, 0.1781529287298107, 0.17262251038245524, 0.17557268084415456, 0.178830312348619, 0.17292867183595118, 0.1843921453768499, 0.1803304182743546, 0.17650569790065107, 0.17220124680031546, 0.17364872335343162, 0.180078526422623, 0.1799078129336733, 0.17516118374393963, 0.18099525611589085, 0.17747406237618168, 0.1759971555676434, 0.1786655868064213, 0.17760066074781655, 0.17639347928567384, 0.1828487204909638]\n",
      "\n",
      "========================\n",
      "Total Class 0 Errors:\n",
      "54\n",
      "========================\n",
      "\n",
      "[-0.8168214824845813, -0.8110904849044421, -0.813288002232884, -0.8165694260678047, -0.8142486168622518, -0.8150505840704027, -0.8181718310594424, -0.8192420375278714, -0.8133182357418478, -0.8137371643051161, -0.8116401429388173, -0.8202578525626865, -0.8137553354836955, -0.816086119286936, -0.8177481617309316, -0.8133240317184244, -0.8154712850986877, -0.820703173527292, -0.8169472699861617, -0.8139256584397443, -0.8136024804868516, -0.8071127287564761, -0.8135976956101255, -0.8177088089171728, -0.8168009430389233, -0.811362418373524, -0.8165838279602748, -0.816545503996455, -0.821318918054548, -0.815415225167078, -0.8146094991192604, -0.8194235409199735, -0.8112124462145419, -0.8116444265224952, -0.8197276781055264, -0.8202172072788373, -0.8134537212571047, -0.8083944822905155, -0.8123687604308786, -0.8093981837098122, -0.8096625584322572, -0.8163122926644477, -0.8186821077208507, -0.8165289080003552, -0.8183246467164426, -0.8173307295402349, -0.816150290582041, -0.8175575778482983, -0.8186432286866596, -0.8222826820892286, -0.8162280446296883, -0.8181386711232244, -0.8192076512919297, -0.8193345083385776]\n",
      "\n",
      "========================\n",
      "Total Class 1 Errors:\n",
      "46\n",
      "========================\n",
      "\n",
      "[0.1787857275487177, 0.177894662620384, 0.17315843196532832, 0.17508356939836545, 0.17324896970865167, 0.17788298066750208, 0.17737381234700267, 0.1710342403883195, 0.1766834693481698, 0.17817224413030996, 0.18237531453412326, 0.17639777805054901, 0.17425502913808177, 0.18005084755611223, 0.17989852488608327, 0.18395388698576343, 0.17879887064313904, 0.1777231855054987, 0.17782220568263207, 0.17839892838709115, 0.1809356890224798, 0.17511143120568395, 0.1770625464728547, 0.1765268728707079, 0.17412618697616022, 0.17492841685340743, 0.1781529287298107, 0.17262251038245524, 0.17557268084415456, 0.178830312348619, 0.17292867183595118, 0.1843921453768499, 0.1803304182743546, 0.17650569790065107, 0.17220124680031546, 0.17364872335343162, 0.180078526422623, 0.1799078129336733, 0.17516118374393963, 0.18099525611589085, 0.17747406237618168, 0.1759971555676434, 0.1786655868064213, 0.17760066074781655, 0.17639347928567384, 0.1828487204909638]\n"
     ]
    }
   ],
   "source": [
    "## question 3c\n",
    "## computing the errors for each output of the NN\n",
    "FinalErrors = []\n",
    "FinaL0 = []\n",
    "FinaL1 = []\n",
    "for i in Output0:\n",
    "    FinalErrors.append(0-i)\n",
    "    FinaL0.append(0- i)\n",
    "for i in Output1:\n",
    "    FinalErrors.append(1- i)\n",
    "    FinaL1.append(1-i)\n",
    "\n",
    "printQues(\"3c\")\n",
    "print('\\n========================')\n",
    "print(\"Total Errors:\")\n",
    "print(len(FinalErrors))\n",
    "print('========================\\n')\n",
    "print(FinalErrors)\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"Total Class 0 Errors:\")\n",
    "print(len(FinaL0))\n",
    "print('========================\\n')\n",
    "print(FinaL0)\n",
    "\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"Total Class 1 Errors:\")\n",
    "print(len(FinaL1))\n",
    "print('========================\\n')\n",
    "print(FinaL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question 3d\n",
    "## calculate for each error in final node\n",
    "## for each theta\n",
    "\n",
    "SecondErrorsNode1 = []  ## to store the errors of each node in the hidden layer\n",
    "SecondErrorsNode2 = []\n",
    "SecondErrorsNode3 = []\n",
    "\n",
    "Node1 = [] ## to store the output of each nodes in the hidden layer\n",
    "Node2 = []\n",
    "Node3 = []\n",
    "for i in range(len(FinaL0)): ## calculating the errors of the NN and each node on class 0\n",
    "        \n",
    "    SecondNode0 = (1 * N1firstThetas[0])+(class0_points_x[i] *N2firstThetas[0] ) + (class0_points_y[i] * N3firstThetas[0])##calculating the error of the 1st nonbias node in the secondlayer on class 0 input\n",
    "    Node1.append(sigmoid(SecondNode0))\n",
    "    error = SecondLayerThetas[1] * FinaL0[i] * (sigmoid(SecondNode0)*(1 - sigmoid(SecondNode0)))\n",
    "    \n",
    "    SecondErrorsNode1.append(error)\n",
    "    \n",
    "    SecondNode1 = (1 * N1firstThetas[1])+(class0_points_x[i] *N2firstThetas[1] ) + (class0_points_y[i] * N3firstThetas[1])\n",
    "    Node2.append(sigmoid(SecondNode1))\n",
    "    error1 = SecondLayerThetas[2] * FinaL0[i] * (sigmoid(SecondNode1)*(1 - sigmoid(SecondNode1)))\n",
    "    \n",
    "    SecondErrorsNode2.append(error1)\n",
    "    \n",
    "    SecondNode2 = (1 * N1firstThetas[2])+(class0_points_x[i] *N2firstThetas[2] ) + (class0_points_y[i] * N3firstThetas[2])\n",
    "    Node3.append(sigmoid(SecondNode2))\n",
    "    error2 = SecondLayerThetas[2] * FinaL0[i] * (sigmoid(SecondNode2)*(1 - sigmoid(SecondNode2)))\n",
    "    \n",
    "    SecondErrorsNode3.append(error2)\n",
    "\n",
    "\n",
    "for i in range(len(FinaL1)):## Calculating the errors of the NN and each node on class 1 \n",
    "    SecondNode0 = (1 * N1firstThetas[0])+(class1_points_x[i] *N2firstThetas[0] ) + (class1_points_y[i] * N3firstThetas[0])\n",
    "    Node1.append(sigmoid(SecondNode0))\n",
    "    error = SecondLayerThetas[1] * FinaL1[i] * (sigmoid(SecondNode0)*(1 - sigmoid(SecondNode0)))\n",
    "    \n",
    "    SecondErrorsNode1.append(error)\n",
    "    \n",
    "    SecondNode1 = (1 * N1firstThetas[1])+(class1_points_x[i] *N2firstThetas[1] ) + (class1_points_y[i] * N3firstThetas[1])\n",
    "    Node2.append(sigmoid(SecondNode1))\n",
    "    error1 = SecondLayerThetas[2] * FinaL1[i] * (sigmoid(SecondNode1)*(1 - sigmoid(SecondNode1)))\n",
    "    \n",
    "    SecondErrorsNode2.append(error1)\n",
    "    \n",
    "    SecondNode2 = (1 * N1firstThetas[2])+(class1_points_x[i] *N2firstThetas[2] ) + (class1_points_y[i] * N3firstThetas[2])\n",
    "    Node3.append(sigmoid(SecondNode2))\n",
    "    error2 = SecondLayerThetas[2] * FinaL1[i] * (sigmoid(SecondNode2)*(1 - sigmoid(SecondNode2)))\n",
    "    \n",
    "    SecondErrorsNode3.append(error2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##question 3D \n",
    "SecondLayerDelta = [0,0,0,0]\n",
    "FirstLayerDeltaNode1 = [0,0,0]\n",
    "FirstLayerDeltaNode2 = [0,0,0]\n",
    "FirstLayerDeltaNode3 = [0,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for  i in range(len(FinalErrors)):\n",
    "    SecondLayerDelta[0] = SecondLayerDelta[0] + 0 *FinalErrors[i]\n",
    "    \n",
    "##for node 1s theta\n",
    "for i in range(len(FinalErrors)):\n",
    "    SecondLayerDelta[1] = SecondLayerDelta[1] + Node1[i]*FinalErrors[i] \n",
    "##for node 2s theta\n",
    "for i in range(len(FinalErrors)):\n",
    "    SecondLayerDelta[2] = SecondLayerDelta[2] + Node2[i]*FinalErrors[i]\n",
    "##for node 3s theta\n",
    "for i in range(len(FinalErrors)):\n",
    "    SecondLayerDelta[3] = SecondLayerDelta[3] + Node3[i]*FinalErrors[i]\n",
    "\n",
    "## for node 1f theta\n",
    "\n",
    "##first for class 0\n",
    "    for x in range (len(SecondErrorsNode1)):\n",
    "        FirstLayerDeltaNode1[0] = FirstLayerDeltaNode1[0] + SecondErrorsNode1[x]\n",
    "        FirstLayerDeltaNode1[1] = FirstLayerDeltaNode1[1] + SecondErrorsNode1[x]\n",
    "        FirstLayerDeltaNode1[2] = FirstLayerDeltaNode1[2] + SecondErrorsNode1[x]\n",
    "\n",
    "## for node 2f theta\n",
    "for i in range(len(FirstLayerDeltaNode2)):\n",
    "    for x in range (len(SecondErrorsNode2)):\n",
    "        FirstLayerDeltaNode2[i] = FirstLayerDeltaNode2[i] + SecondErrorsNode2[x]\n",
    "## for node 3f theta\n",
    "for i in range(len(FirstLayerDeltaNode3)):\n",
    "    for x in range (len(SecondErrorsNode3)):\n",
    "        FirstLayerDeltaNode3[i] = FirstLayerDeltaNode3[i] + SecondErrorsNode3[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (3d)\n",
      "=============\n",
      "\n",
      "========================\n",
      "Second Layer, Node 1:\n",
      "========================\n",
      "\n",
      "[-0.04239609127244051, -0.04164806649471959, -0.04381035491786645, -0.040495882893662905, -0.042490156159398516, -0.04414597072343213, -0.03514961791448842, -0.041134282502404945, -0.040952126131427326, -0.04472602407662021, -0.045138955753424075, -0.03985101599074819, -0.04306314022724346, -0.04211338547325261, -0.038805625462709756, -0.04566747181149461, -0.044368338444635176, -0.03401106535282942, -0.040902680814042205, -0.043519086999752196, -0.043108732547223555, -0.046832876252912506, -0.04042017536326768, -0.04393401880524545, -0.04106940070561126, -0.04524777343847953, -0.03984504691346351, -0.04315502368477261, -0.040725158111638154, -0.03966156375465476, -0.0368384067613307, -0.0384115256614478, -0.04196090655610383, -0.04340933472495535, -0.039906203899114805, -0.04192118229385598, -0.04363882641007534, -0.045676782933277864, -0.044077620275870304, -0.04497388970018752, -0.04613912089736438, -0.04074824017672406, -0.041480021612305566, -0.04250706769058816, -0.03914298174652896, -0.0404783749050824, -0.04295973759571881, -0.03506221001596261, -0.0349977449205046, -0.038352162168761875, -0.040081410594327765, -0.04397202792920563, -0.04106523470503489, -0.04096101100902695, 0.008030886550139026, 0.008052123196392943, 0.006776020390340308, 0.007394973407322538, 0.007020634390099064, 0.007481244310284623, 0.008764516257173817, 0.00611931325605315, 0.007953879828115736, 0.009168169372177248, 0.008478837624909225, 0.008169486638414783, 0.0072972909557486336, 0.0076313661830725715, 0.008031469025276537, 0.008649497526906334, 0.008102576516576946, 0.007523724570440802, 0.00768842406458226, 0.007429526537305217, 0.008189657474625365, 0.007036655249381109, 0.007757954693936733, 0.008278836419181382, 0.007725251177054709, 0.007053190159021518, 0.008991514430879715, 0.00661226540114852, 0.008429286419489595, 0.007473170751904889, 0.006886209564508404, 0.008669763104060318, 0.009596445977551073, 0.008111805025829668, 0.006749458770183559, 0.006763855362721103, 0.007667597890607725, 0.007750845152930746, 0.007841111867223647, 0.008260503466244712, 0.008925183738003033, 0.007050527712889051, 0.007527151691067713, 0.008572842414828816, 0.008558727842954432, 0.008448336580107907]\n",
      "\n",
      "========================\n",
      "Second Layer, Node 2:\n",
      "========================\n",
      "\n",
      "[-0.04034150076462016, -0.03932257518336165, -0.04096707770263808, -0.03901285640712332, -0.040172366687375456, -0.041330110845730864, -0.035216755167488505, -0.03972393605623672, -0.0390293141730127, -0.04159099568467207, -0.04168857135653906, -0.03893985563209964, -0.040513779475694414, -0.040083088262089096, -0.03792309607370068, -0.04214276247103802, -0.04150687591876587, -0.03461779478233359, -0.039334214024346545, -0.04082950470126338, -0.040531131655921884, -0.04241559614385809, -0.038678450516343305, -0.0414260573307673, -0.0394357331596026, -0.041736075166990697, -0.038553265297130414, -0.040818770917107686, -0.03966479521658583, -0.038307299494843, -0.03613944381194904, -0.03781558545208435, -0.039550198778420954, -0.04056913545567804, -0.03892121425530999, -0.04035688395593067, -0.040868622562257616, -0.04179154288671928, -0.04106664464245071, -0.04141785471179944, -0.042165443498691974, -0.039164890454945096, -0.03990314065132831, -0.040388585951038614, -0.038227707390393946, -0.03907562677083399, -0.040654733509609374, -0.03508103014939371, -0.03515132964526599, -0.0381013409247962, -0.03868651066658197, -0.04148898830265031, -0.03967303689825198, -0.03961451232454653, 0.008032235136270289, 0.008058954901392898, 0.0071481006995740915, 0.007601350418885386, 0.007341837360950169, 0.007624072833427294, 0.008572972921960293, 0.00665436953342321, 0.008001263261243818, 0.008838785251248368, 0.008326339181018853, 0.008162993383405362, 0.007539862203882616, 0.007709896010760151, 0.008019160207630008, 0.008437515408965979, 0.008085608321625125, 0.007659574445220799, 0.007785324265407398, 0.007575735968673417, 0.008126114237827912, 0.007319249675640412, 0.007849070751119057, 0.008240364785828845, 0.007867363352231645, 0.0073357831790997596, 0.008721778158901976, 0.007026525401677779, 0.008356780946732412, 0.007603560946213944, 0.007241404798872014, 0.008448536062201828, 0.009110030813568613, 0.008119761322832025, 0.007147111762841091, 0.007128130426007899, 0.007737763909125785, 0.007804662859513435, 0.007938212981931467, 0.008178439948937195, 0.008681146564610888, 0.0073144002774026, 0.0076482814328484505, 0.00843834032641752, 0.00843913596251051, 0.008299086177645925]\n",
      "\n",
      "========================\n",
      "Second Layer, Node 3:\n",
      "========================\n",
      "\n",
      "[-0.027073127982423673, -0.029437480612897728, -0.029671534254126945, -0.026150580787821617, -0.02842787937642988, -0.02900323991666131, -0.02256957262356877, -0.025085598939699343, -0.028004999380103743, -0.030010610967986438, -0.031269526151526346, -0.023852467373765385, -0.029001910282542148, -0.027292773927318083, -0.024646445466809486, -0.030805394096585226, -0.028923843115565742, -0.020731552803024727, -0.02617833485096814, -0.029187707975561333, -0.029102904074771545, -0.03435898253292935, -0.02757559075006114, -0.027488836258506122, -0.02634502290890743, -0.03146697681715135, -0.02579177320467101, -0.02765119017255896, -0.023707894330721353, -0.026277622012491068, -0.025166954867312977, -0.023566577232373483, -0.029561156598590228, -0.0302092380308855, -0.024171851170764706, -0.024967686060197825, -0.029488765956668255, -0.033060512328003076, -0.030271832619023647, -0.03217937683668145, -0.0328098798485709, -0.026419033060834214, -0.025576760215511567, -0.02728809046081632, -0.024523371148075918, -0.0257496497197406, -0.027742975856169007, -0.02282974616767865, -0.022258524681703445, -0.021965319570801486, -0.026099015421705767, -0.027277680370721917, -0.025067339694496326, -0.02494232392069523, 0.004755998307132488, 0.00465499186865986, 0.00348736606133057, 0.003995642745374684, 0.0036005926424866864, 0.004382841379659849, 0.004939121158764962, 0.002961582518827133, 0.004454681785054195, 0.005253805759137878, 0.005419672869745259, 0.004519778765958966, 0.003847196476124363, 0.004715936432488997, 0.00489317044097394, 0.005697899100318875, 0.004792583916264767, 0.00438318667505526, 0.004472700794444179, 0.004421123229795076, 0.005098142499655085, 0.0038414433327132423, 0.004410798230451874, 0.004588818364520037, 0.004017814818080507, 0.0038259979968839185, 0.005157890537122597, 0.003353124610289627, 0.004534914985436771, 0.004493706705081388, 0.003503859222455997, 0.005760689918978821, 0.005768726804319288, 0.004506391618371988, 0.0033553181955654388, 0.003543502721104207, 0.004736848098451795, 0.004756854745813862, 0.004205913558905672, 0.005141062811338482, 0.005034482561373879, 0.003956232544725297, 0.004499460200327341, 0.004872337203644873, 0.004707142817186472, 0.005460761396019171]\n",
      "\n",
      "\n",
      "========================\n",
      "First Layer, Node 1:\n",
      "========================\n",
      "\n",
      "[-188.64590252375578, -188.64590252375578, -188.64590252375578]\n",
      "\n",
      "========================\n",
      "First Layer, Node 2:\n",
      "========================\n",
      "\n",
      "[-1.7784312211427047, -1.7784312211427047, -1.7784312211427047]\n",
      "\n",
      "========================\n",
      "First Layer, Node 3:\n",
      "========================\n",
      "\n",
      "[-1.2635029263597617, -1.2635029263597617, -1.2635029263597617]\n"
     ]
    }
   ],
   "source": [
    "printQues(\"3d\")\n",
    "print('\\n========================')\n",
    "print(\"Second Layer, Node 1:\")\n",
    "print('========================\\n')\n",
    "print(SecondErrorsNode1)\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"Second Layer, Node 2:\")\n",
    "print('========================\\n')\n",
    "print(SecondErrorsNode2)\n",
    "\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"Second Layer, Node 3:\")\n",
    "print('========================\\n')\n",
    "print(SecondErrorsNode3)\n",
    "\n",
    "print()\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"First Layer, Node 1:\")\n",
    "print('========================\\n')\n",
    "print(FirstLayerDeltaNode1)\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"First Layer, Node 2:\")\n",
    "print('========================\\n')\n",
    "print(FirstLayerDeltaNode2)\n",
    "\n",
    "\n",
    "print('\\n========================')\n",
    "print(\"First Layer, Node 3:\")\n",
    "print('========================\\n')\n",
    "print(FirstLayerDeltaNode3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question (3e)\n",
      "=============\n",
      "\n",
      "[array([-0.00423961, -0.00403415, -0.00270731]), array([-0.00416481, -0.00393226, -0.00294375]), array([-0.00438104, -0.00409671, -0.00296715]), array([-0.00404959, -0.00390129, -0.00261506])]\n"
     ]
    }
   ],
   "source": [
    "#Question 3e\n",
    "\n",
    "q3NN.setWeights(thetaMatrix)\n",
    "q3NN.setActivationFunction(sigmoid)\n",
    "outputLst = []\n",
    "\n",
    "for i in range(len(SecondLayerDelta)):\n",
    "    outputLst.append(np.dot(learningRate,([SecondErrorsNode1[i],SecondErrorsNode2[i], SecondErrorsNode3[i]])))\n",
    "\n",
    "printQues(\"3e\")\n",
    "print()\n",
    "print(outputLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Question 3F\n",
    "\n",
    "## updating thetas\n",
    "for i in range(len(SecondLayerDelta)):\n",
    "    SecondLayerThetas[i] = SecondLayerThetas[i] + learningRate*(SecondLayerDelta[i])\n",
    "\n",
    "\n",
    "for i in range(len(FirstLayerDeltaNode1)):\n",
    "    N1firstThetas[i] = N1firstThetas[i] + learningRate*(FirstLayerDeltaNode1[i])\n",
    "    \n",
    "for i in range(len(FirstLayerDeltaNode2)):\n",
    "    N2firstThetas[i] = N2firstThetas[i] + learningRate*(FirstLayerDeltaNode2[i])\n",
    "    \n",
    "for i in range(len(FirstLayerDeltaNode3)):\n",
    "    N3firstThetas[i] = N3firstThetas[i] + learningRate*(FirstLayerDeltaNode3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "##Question 3G\n",
    "\n",
    "def trainNetwork(network, epsi,maxCount, class0x, class0y, class1x, class1y, actiFunc, thetaMatrix,learningRate):\n",
    "    count = 0\n",
    "    Difference = 1000\n",
    "    network.resetNetwork()\n",
    "    network.setWeights(thetaMatrix)\n",
    "    network.setActivationFunction(actiFunc)\n",
    "\n",
    "    while count < maxCount and Difference > epsi:\n",
    "\n",
    "        maxIterations = max(len(class0x), len(class1x))\n",
    "        class0Size = len(class0x)\n",
    "        class1Size = len(class1x)\n",
    "\n",
    "        old = copy.deepcopy(network.getWeights())\n",
    "        new = copy.deepcopy(network.getWeights())\n",
    "        for i in range(maxIterations):\n",
    "\n",
    "            if (i < class0Size):\n",
    "                arr = [class0x[i],class0y[i]]\n",
    "                \n",
    "                network.setInputLayer(arr)\n",
    "                network.forwardPropagation()\n",
    "                network.backwardPropagation(0, learningRate)\n",
    "                \n",
    "                old = copy.deepcopy(new)\n",
    "                new = network.getWeights()\n",
    "                Difference = norm2(new,old)\n",
    "\n",
    "            if (i < class1Size):\n",
    "                arr = [class1x[i],class1y[i]]\n",
    "                \n",
    "                network.setInputLayer(arr)\n",
    "                network.forwardPropagation()\n",
    "                network.backwardPropagation(1, learningRate)\n",
    "                \n",
    "                old = copy.deepcopy(new)\n",
    "                new = network.getWeights()\n",
    "                Difference = norm2(new,old)\n",
    "\n",
    "            if(Difference < epsi):\n",
    "                break\n",
    "\n",
    "        count += 1\n",
    "    return count\n",
    "    \n",
    "print(trainNetwork(q3NN, 0.05, 1000, class0_points_x, class0_points_y,class1_points_x,class1_points_y, sigmoid, thetaMatrix, learningRate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t65\t0\n",
      "1\t35\t0\n",
      "\n",
      "Accuracy is 65.0%\n",
      "====================\n",
      "\n",
      "I noticed that it is always printintout class 0, I think this is because the learning rate and epsilon values were not ideal and therefore the neural network never train properly/accurately\n"
     ]
    }
   ],
   "source": [
    "##Question 3H\n",
    "\n",
    "# Generate 100 data points\n",
    "validation0_points_x = []\n",
    "validation0_points_y = []\n",
    "\n",
    "validation1_points_x = []\n",
    "validation1_points_y = []\n",
    "    \n",
    "dataPoints(validation0_points_x, validation0_points_y, validation1_points_x, validation1_points_y)\n",
    "\n",
    "# Get output\n",
    "OutP0 = []\n",
    "OutP1 = []\n",
    "\n",
    "for i in range(len(validation0_points_x)):\n",
    "    x = validation0_points_x[i]\n",
    "    y = validation0_points_y[i]\n",
    "    arr = [x,y]\n",
    "    q3NN.setInputLayer(arr)\n",
    "    q3NN.forwardPropagation()\n",
    "    OutP0.append(q3NN.getOutput()) \n",
    "\n",
    "for i in range(len(validation1_points_x)):\n",
    "    x = validation1_points_x[i]\n",
    "    y = validation1_points_y[i]\n",
    "    arr = [x,y]\n",
    "    q3NN.setInputLayer(arr)\n",
    "    q3NN.forwardPropagation()\n",
    "    OutP1.append(q3NN.getOutput()) \n",
    "\n",
    "# Round the output points\n",
    "\n",
    "class0_output = []\n",
    "class1_output = []\n",
    "\n",
    "correctClass0 = 0\n",
    "incorrectClass0 = 0\n",
    "\n",
    "correctClass1 = 0\n",
    "incorrectClass1 = 0\n",
    "\n",
    "for i in range(len(OutP0)):\n",
    "    \n",
    "    \n",
    "    # data points class 0 \n",
    "    if (OutP0[i] >= 0.5):\n",
    "        incorrectClass0 += 1\n",
    "        class0_output.append(1)\n",
    "    else:\n",
    "        correctClass0 += 1\n",
    "        class0_output.append(0)\n",
    "\n",
    "\n",
    "for i in range(len(OutP1)):\n",
    "    # data points class 1 \n",
    "    if (OutP1[i] >= 0.5):\n",
    "        correctClass1 += 1\n",
    "        class1_output.append(1)\n",
    "    else:\n",
    "        incorrectClass1 += 1\n",
    "        class1_output.append(0)\n",
    "        \n",
    "        \n",
    "printConfusionMatrix(correctClass0, incorrectClass0,correctClass1,incorrectClass1)\n",
    "\n",
    "print(\"I noticed that it is always printintout class 0, I think this is because the learning rate and epsilon values were not ideal and therefore the neural network never train properly/accurately\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "a is: 0.1\n",
      "Epsilon is: 0.5\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.1\n",
      "Epsilon is: 0.05\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.1\n",
      "Epsilon is: 0.01\n",
      "=====================\n",
      "\n",
      "1000\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.1\n",
      "Epsilon is: 0.005\n",
      "=====================\n",
      "\n",
      "1000\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.1\n",
      "Epsilon is: 0.001\n",
      "=====================\n",
      "\n",
      "1000\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.01\n",
      "Epsilon is: 0.5\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.01\n",
      "Epsilon is: 0.05\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.01\n",
      "Epsilon is: 0.01\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.01\n",
      "Epsilon is: 0.005\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.01\n",
      "Epsilon is: 0.001\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.005\n",
      "Epsilon is: 0.5\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.005\n",
      "Epsilon is: 0.05\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.005\n",
      "Epsilon is: 0.01\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.005\n",
      "Epsilon is: 0.005\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.005\n",
      "Epsilon is: 0.001\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.001\n",
      "Epsilon is: 0.5\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.001\n",
      "Epsilon is: 0.05\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.001\n",
      "Epsilon is: 0.01\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.001\n",
      "Epsilon is: 0.005\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "=====================\n",
      "a is: 0.001\n",
      "Epsilon is: 0.001\n",
      "=====================\n",
      "\n",
      "1\n",
      "\n",
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t53\t0\n",
      "1\t47\t0\n",
      "\n",
      "Accuracy is 53.0%\n",
      "====================\n",
      "\n",
      "\n",
      "\n",
      "Optimal Learning Rate is: 0.1\n",
      "Optimal Epsilon is: 0.5\n"
     ]
    }
   ],
   "source": [
    "##Question 3I\n",
    "\n",
    "aVals = [0.1, 0.01, 0.005, 0.001]\n",
    "epsilonVals = [0.5, 0.05, 0.01, 0.005, 0.001]\n",
    "maxAccu = 0\n",
    "optimalLearningRate = 0\n",
    "optimalEpsilon = 0\n",
    "\n",
    "# Generate 100 data points\n",
    "validation0_points_x = []\n",
    "validation0_points_y = []\n",
    "\n",
    "validation1_points_x = []\n",
    "validation1_points_y = []\n",
    "    \n",
    "dataPoints(validation0_points_x, validation0_points_y, validation1_points_x, validation1_points_y)\n",
    "\n",
    "\n",
    "\n",
    "for aVal in aVals:\n",
    "    for epsilonVal in epsilonVals:\n",
    "        print(\"=====================\")\n",
    "        print(\"a is: \" + str(aVal))\n",
    "        print(\"Epsilon is: \" + str(epsilonVal))\n",
    "        print(\"=====================\\n\")\n",
    "        print(trainNetwork(q3NN, epsilonVal, 1000, class0_points_x, class0_points_y,class1_points_x,class1_points_y, sigmoid, thetaMatrix, aVal))\n",
    "        print()\n",
    "        \n",
    "        # Get output\n",
    "        OutP0 = []\n",
    "        OutP1 = []\n",
    "\n",
    "        for i in range(len(validation0_points_x)):\n",
    "            x = validation0_points_x[i]\n",
    "            y = validation0_points_y[i]\n",
    "            arr = [x,y]\n",
    "            q3NN.setInputLayer(arr)\n",
    "            q3NN.forwardPropagation()\n",
    "            OutP0.append(q3NN.getOutput()) \n",
    "\n",
    "        for i in range(len(validation1_points_x)):\n",
    "            x = validation1_points_x[i]\n",
    "            y = validation1_points_y[i]\n",
    "            arr = [x,y]\n",
    "            q3NN.setInputLayer(arr)\n",
    "            q3NN.forwardPropagation()\n",
    "            OutP1.append(q3NN.getOutput()) \n",
    "\n",
    "        # Round the output points\n",
    "\n",
    "        class0_output = []\n",
    "        class1_output = []\n",
    "\n",
    "        correctClass0 = 0\n",
    "        incorrectClass0 = 0\n",
    "\n",
    "        correctClass1 = 0\n",
    "        incorrectClass1 = 0\n",
    "\n",
    "        for i in range(len(OutP0)):\n",
    "\n",
    "\n",
    "            # data points class 0 \n",
    "            if (OutP0[i] >= 0.5):\n",
    "                incorrectClass0 += 1\n",
    "                class0_output.append(1)\n",
    "            else:\n",
    "                correctClass0 += 1\n",
    "                class0_output.append(0)\n",
    "\n",
    "\n",
    "        for i in range(len(OutP1)):\n",
    "            # data points class 1 \n",
    "            if (OutP1[i] >= 0.5):\n",
    "                correctClass1 += 1\n",
    "                class1_output.append(1)\n",
    "            else:\n",
    "                incorrectClass1 += 1\n",
    "                class1_output.append(0)\n",
    "\n",
    "\n",
    "        accu = printConfusionMatrix(correctClass0, incorrectClass0,correctClass1,incorrectClass1)\n",
    "        print()\n",
    "        \n",
    "        if (accu > maxAccu):\n",
    "            maxAccu = accu\n",
    "            optimalLearningRate = aVal\n",
    "            optimalEpsilon = epsilonVal\n",
    "            \n",
    "print()\n",
    "print(\"Optimal Learning Rate is: \" + str(optimalLearningRate))\n",
    "print(\"Optimal Epsilon is: \" + str(optimalEpsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "====================\n",
      "Class\t0\t1\n",
      "0\t44\t0\n",
      "1\t56\t0\n",
      "\n",
      "Accuracy is 44.0%\n",
      "====================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Question 3J\n",
    "trainNetwork(q3NN, optimalEpsilon, 1000, class0_points_x, class0_points_y,class1_points_x,class1_points_y, sigmoid, thetaMatrix, optimalLearningRate)\n",
    "\n",
    "# Generate 100 data points\n",
    "test0_points_x = []\n",
    "test0_points_y = []\n",
    "\n",
    "test1_points_x = []\n",
    "test1_points_y = []\n",
    "    \n",
    "dataPoints(test0_points_x, test0_points_y, test1_points_x, test1_points_y)\n",
    "# Get output\n",
    "OutP0 = []\n",
    "OutP1 = []\n",
    "\n",
    "for i in range(len(test0_points_x)):\n",
    "    x = test0_points_x[i]\n",
    "    y = test0_points_y[i]\n",
    "    arr = [x,y]\n",
    "    q3NN.setInputLayer(arr)\n",
    "    q3NN.forwardPropagation()\n",
    "    OutP0.append(q3NN.getOutput()) \n",
    "\n",
    "for i in range(len(test1_points_x)):\n",
    "    x = test1_points_x[i]\n",
    "    y = test1_points_y[i]\n",
    "    arr = [x,y]\n",
    "    q3NN.setInputLayer(arr)\n",
    "    q3NN.forwardPropagation()\n",
    "    OutP1.append(q3NN.getOutput()) \n",
    "\n",
    "# Round the output points\n",
    "\n",
    "class0_output = []\n",
    "class1_output = []\n",
    "\n",
    "correctClass0 = 0\n",
    "incorrectClass0 = 0\n",
    "\n",
    "correctClass1 = 0\n",
    "incorrectClass1 = 0\n",
    "\n",
    "for i in range(len(OutP0)):\n",
    "    \n",
    "    \n",
    "    # data points class 0 \n",
    "    if (OutP0[i] >= 0.5):\n",
    "        incorrectClass0 += 1\n",
    "        class0_output.append(1)\n",
    "    else:\n",
    "        correctClass0 += 1\n",
    "        class0_output.append(0)\n",
    "\n",
    "\n",
    "for i in range(len(OutP1)):\n",
    "    # data points class 1 \n",
    "    if (OutP1[i] >= 0.5):\n",
    "        correctClass1 += 1\n",
    "        class1_output.append(1)\n",
    "    else:\n",
    "        incorrectClass1 += 1\n",
    "        class1_output.append(0)\n",
    "        \n",
    "        \n",
    "printConfusionMatrix(correctClass0, incorrectClass0,correctClass1,incorrectClass1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3(k)\n",
    "\n",
    "# It is important to have all 3 common data sets because,\n",
    "\n",
    "# Training Set\n",
    "#=============\n",
    "\n",
    "# We need an actual data set to let our algorithm learn from \n",
    "# otherwise I algorithm would not be able to predict anything\n",
    "# therefore, having no use to us (ML will be useless)\n",
    "\n",
    "# Validation Set\n",
    "#===============\n",
    "\n",
    "# As seen in this lab, different a (or alpha) values and threshold values\n",
    "# (for our stopping condition) can and will majorly impact how good our \n",
    "# algorithm will be at predicting values. We therefore use the validation\n",
    "# data set to go through and find the most effective a (or alpha) and \n",
    "# threshold values\n",
    "\n",
    "# We use it for fine-tuning our hyperparameters!\n",
    "\n",
    "# Testing Set\n",
    "#============\n",
    "\n",
    "# We need to actually put our algorithm into action! We need to make sure\n",
    "# we never overfit our data. We simulate what a real-life example would be\n",
    "# by merely giving a data set the algorithm never interact with before.\n",
    "# i.e. the testing data set. We can tell if we overfitted our data\n",
    "# and also we can just see how our algorithm does in general without having\n",
    "# to physically get/wait for real world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3(k)\n",
    "\n",
    "### It is important to have all 3 common data sets because,\n",
    "\n",
    "### Training Set\n",
    "=============\n",
    "\n",
    "We need an actual data set to let our algorithm learn from \n",
    "otherwise I algorithm would not be able to predict anything\n",
    "therefore, having no use to us (ML will be useless)\n",
    "\n",
    "### Validation Set\n",
    "===============\n",
    "\n",
    "As seen in this lab, different a (or alpha) values and threshold values\n",
    "(for our stopping condition) can and will majorly impact how good our \n",
    "algorithm will be at predicting values. We therefore use the validation\n",
    "data set to go through and find the most effective a (or alpha) and \n",
    "threshold values\n",
    "\n",
    "We use it for fine-tuning our hyperparameters!\n",
    "\n",
    "### Testing Set\n",
    "============\n",
    "\n",
    "We need to actually put our algorithm into action! We need to make sure\n",
    "we never overfit our data. We simulate what a real-life example would be\n",
    "by merely giving a data set the algorithm never interact with before.\n",
    "i.e. the testing data set. We can tell if we overfitted our data\n",
    "and also we can just see how our algorithm does in general without having\n",
    "to physically get/wait for real world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
